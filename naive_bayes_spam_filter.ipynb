{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam Filter For SMS Messages With Naive Bayes Algorithm\n",
    "\n",
    "The goal of this project is to create a spam filter that can classify SMS messages as either SPAM or HAM(non-spam), using the multinomial Naive Bayes algorithm.\n",
    "\n",
    "**Our target is to create a spam filter that can classify new messages with an accuracy greater than 80%**\n",
    "\n",
    "For our program to classify the messages, we must first train it how humans classify messages as spam or ham. To do this we'll use a dataset of 5,572 SMS messages that are already classified by humans. You can download the dataset on [The UCI Machine Learning Repository here](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection) and learn more about it [here](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition).\n",
    "\n",
    "Lets start by reading and exploring the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Rows: 5572\n",
      "# Columns: 2\n",
      "\n",
      "  Label                                                SMS\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "#Read the SMSSpamCollection Dataset into a Pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"SMSSpamCollection\", header=None, sep='\\t')\n",
    "\n",
    "#set column names\n",
    "df.columns = ['Label','SMS']\n",
    "\n",
    "#print number of rows and columns\n",
    "print(\"# Rows: {}\\n# Columns: {}\\n\".format(df.shape[0], df.shape[1]))\n",
    "#print first five rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ham/Spam Percentage\n",
    "\n",
    "Let's find what percentage of the messages are spam and what percentage are ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham count: 4825\n",
      "spam count: 747\n",
      "ham percentage: 87%\n",
      "spam percentage: 13%\n"
     ]
    }
   ],
   "source": [
    "#count ham and spam\n",
    "num_ham = df[df['Label']== 'ham'].shape[0]\n",
    "num_spam = df[df['Label']== 'spam'].shape[0]\n",
    "print(\"ham count: {}\".format(num_ham))\n",
    "print(\"spam count: {}\".format(num_spam))\n",
    "\n",
    "#calculate ham and spam percentages.\n",
    "ham_pct = num_ham / len(df) * 100\n",
    "spam_pct = num_spam / len(df) * 100\n",
    "\n",
    "print(\"ham percentage: {}%\".format(round(ham_pct)))\n",
    "print(\"spam percentage: {}%\".format(round(spam_pct)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split for Evaluating the Algorithm\n",
    "\n",
    "To evaluate the performance of our spam filter we'll split the dataset into a train set and a test set.\n",
    "\n",
    "- **Training set** to fit the model (our spam filter, which is Naive Bayes).\n",
    "\n",
    "\n",
    "- **Testing set** to test the performance of the model. We'll compare predictions made on the test set with the true labels from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train rows: 4458\n",
      "num of test rows: 1114\n",
      "\n",
      "train_set last five rows\n",
      "\n",
      "      Label                                                SMS\n",
      "4453   ham  Sorry, I'll call later in meeting any thing re...\n",
      "4454   ham  Babe! I fucking love you too !! You know? Fuck...\n",
      "4455  spam  U've been selected to stay in 1 of 250 top Bri...\n",
      "4456   ham  Hello my boytoy ... Geeee I miss you already a...\n",
      "4457   ham                           Wherre's my boytoy ? :-(\n",
      "==============================\n",
      "\n",
      "test_set first five rows\n",
      "\n",
      "   Label                                                SMS\n",
      "0   ham          Later i guess. I needa do mcat study too.\n",
      "1   ham             But i haf enuff space got like 4 mb...\n",
      "2  spam  Had your mobile 10 mths? Update to latest Oran...\n",
      "3   ham  All sounds good. Fingers . Makes it difficult ...\n",
      "4   ham  All done, all handed in. Don't know if mega sh...\n"
     ]
    }
   ],
   "source": [
    "#Randomize the entire dataset.\n",
    "rand_df = df.sample(frac=1, random_state=1)\n",
    "\n",
    "#Split data 80% for training 20% for testing and reset index.\n",
    "train_set = rand_df[0:4458].reset_index(drop=True)\n",
    "test_set = rand_df[4458:].reset_index(drop=True)\n",
    "\n",
    "#view the train and test datasets\n",
    "print(\"num of train rows: {}\\nnum of test rows: {}\\n\".format(train_set.shape[0], test_set.shape[0]))\n",
    "print(\"train_set last five rows\\n\\n\",train_set.tail())\n",
    "print(\"===\"*10)\n",
    "print(\"\\ntest_set first five rows\\n\\n\", test_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train spam and ham pct: \n",
      "ham     87.0\n",
      "spam    13.0\n",
      "Name: Label, dtype: float64\n",
      "\n",
      "test spam and ham pct: \n",
      "ham     87.0\n",
      "spam    13.0\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#calculate and print the percentage of spam and ham in both the \n",
    "#training and the test set\n",
    "train_spam_and_ham = train_set['Label'].value_counts(normalize=True)\n",
    "print(\"train spam and ham pct: \\n{}\\n\".format(round(train_spam_and_ham * 100)))\n",
    "\n",
    "test_spam_and_ham = test_set['Label'].value_counts(normalize=True)\n",
    "print(\"test spam and ham pct: \\n{}\".format(round(test_spam_and_ham * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was split proportionally so we can continue.\n",
    "\n",
    "### Data Cleaning\n",
    "\n",
    "Before we can train our model on the training set, we need to put it in a format that is easy to extract the information we need.\n",
    "\n",
    "Instead of just two columns \"Label\" and \"SMS\", we'll add new columns, one for every unique word in all of the messages. The input values will be the number of words in the message for that row.\n",
    "\n",
    "First a quick reminder of data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       Yep, by the pretty sculpture\n",
       "1   ham      Yes, princess. Are you going to make me moan?\n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent.\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first five of the train_set\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by removing all the punctuation and making all letters in every word lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation.\n",
    "train_set['SMS'] = train_set['SMS'].str.replace('\\W', ' ')\n",
    "#Make all words lowercase\n",
    "train_set['SMS'] = train_set['SMS'].str.lower()\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll create a vocabulary for the messages in the training set. The vocabulary is the set of all unique words across all the mesasages in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['foley', '02', 'strongly', 'perpetual', 'fish', 'conserve', 'series', 'farm', 'embarassed', 'vale', 'wylie', 'drunk', 'swhrt', 'deviousbitch', 'clark', 'sat', 'chicken', 'desparate', 'checking', 'hi']\n",
      "7783\n"
     ]
    }
   ],
   "source": [
    "#transform messages to a list of words that are strings.\n",
    "train_set['SMS'] = train_set['SMS'].str.split()\n",
    "\n",
    "#initialize a list to hold the vocabulary.\n",
    "vocabulary = []\n",
    "\n",
    "#loop over words in messages and add to vocabulary\n",
    "for lis in train_set['SMS']:\n",
    "    for w in lis:\n",
    "        vocabulary.append(w)\n",
    "        \n",
    "#remove duplicates by transforming vocabulary to a set.\n",
    "set_vocabulary = set(vocabulary)\n",
    "#transform vocabulary back into a list.\n",
    "vocabulary = list(set_vocabulary)\n",
    "print(vocabulary[:20])\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our vocabulary, we need to create a column for each unique word in our final DataFrame, filled with the number of words in each message.\n",
    "\n",
    "To achieve this we'll first create a dictionary with keys as unique words from the vocabulary and the values will be a list the length of the training set, each index in the list will record the number of times the unique word appear in the messages with that same index. \n",
    "\n",
    "We'll then transform the dictionary into a DataFrame and finally \n",
    "concatenate it with our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>foley</th>\n",
       "      <th>02</th>\n",
       "      <th>strongly</th>\n",
       "      <th>perpetual</th>\n",
       "      <th>fish</th>\n",
       "      <th>conserve</th>\n",
       "      <th>series</th>\n",
       "      <th>farm</th>\n",
       "      <th>...</th>\n",
       "      <th>lapdancer</th>\n",
       "      <th>friendship</th>\n",
       "      <th>youdoing</th>\n",
       "      <th>losers</th>\n",
       "      <th>09058094454</th>\n",
       "      <th>recognises</th>\n",
       "      <th>okday</th>\n",
       "      <th>4ward</th>\n",
       "      <th>09061701461</th>\n",
       "      <th>nigeria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  foley  02  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]      0   0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...      0   0   \n",
       "2   ham                    [welp, apparently, he, retired]      0   0   \n",
       "3   ham                                           [havent]      0   0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...      0   0   \n",
       "\n",
       "   strongly  perpetual  fish  conserve  series  farm  ...  lapdancer  \\\n",
       "0         0          0     0         0       0     0  ...          0   \n",
       "1         0          0     0         0       0     0  ...          0   \n",
       "2         0          0     0         0       0     0  ...          0   \n",
       "3         0          0     0         0       0     0  ...          0   \n",
       "4         0          0     0         0       0     0  ...          0   \n",
       "\n",
       "   friendship  youdoing  losers  09058094454  recognises  okday  4ward  \\\n",
       "0           0         0       0            0           0      0      0   \n",
       "1           0         0       0            0           0      0      0   \n",
       "2           0         0       0            0           0      0      0   \n",
       "3           0         0       0            0           0      0      0   \n",
       "4           0         0       0            0           0      0      0   \n",
       "\n",
       "   09061701461  nigeria  \n",
       "0            0        0  \n",
       "1            0        0  \n",
       "2            0        0  \n",
       "3            0        0  \n",
       "4            0        0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dict with unique words for keys and a list the len of the\n",
    "#training set filled with zeros as the values.\n",
    "word_counts_per_sms = {unique_word: [0]* len(train_set['SMS'])\n",
    "                      for unique_word in vocabulary}\n",
    "\n",
    "#count words in mesgs and update the word_count_per_sms dict.\n",
    "for index, sms in enumerate(train_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "        \n",
    "\n",
    "#Transform word_counts_per_sms into a dataframe\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "\n",
    "#concat to the training set\n",
    "train_set = pd.concat([train_set, word_counts], axis=1)\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating The Spam Filter\n",
    "\n",
    "Now that we've cleaned the data and have a training set to work with, we can start building our spam filter. Below are the two probability equation we'll need to clasify our messages as spam or ham:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam) \\\\\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "\\end{equation}\n",
    "\n",
    "To calculate P(wi|Spam) and P(wi|Ham) inside the formulas above, we'll need to use these equations:\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} \\\\\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "Here's a summary of the terms in the equations above:\n",
    "\n",
    "\\begin{aligned}\n",
    "&N_{w_i|Spam} = \\text{the number of times the word } w_i \\text{ occurs in spam messages} \\\\\n",
    "&N_{w_i|Spam^C} = \\text{the number of times the word } w_i \\text{ occurs in non-spam messages} \\\\\n",
    "\\\\\n",
    "&N_{Spam} = \\text{total number of words in spam messages} \\\\\n",
    "&N_{Spam^C} = \\text{total number of words in non-spam messages} \\\\\n",
    "\\\\\n",
    "&N_{Vocabulary} = \\text{total number of words in the vocabulary} \\\\\n",
    "&\\alpha = 1 \\ \\ \\ \\ (\\alpha \\text{ is a smoothing parameter})\n",
    "\\end{aligned}\n",
    "\n",
    "P(Spam), P(Ham), NSpam, NHam and NVocabulary in the four equations will have the same values for every new message, so let's calculate them now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(spam) = 0.13\n",
      "P(ham) = 0.87\n"
     ]
    }
   ],
   "source": [
    "#isolating spam messages in training set.\n",
    "spam_sms = train_set[train_set['Label'] == 'spam']\n",
    "#isolating ham messages in training set.\n",
    "ham_sms = train_set[train_set['Label'] == 'ham']\n",
    "\n",
    "#calculating NSpam.\n",
    "n_spam = spam_sms['SMS'].apply(len).sum()\n",
    "#calculating NHam.\n",
    "n_ham = ham_sms['SMS'].apply(len).sum()        \n",
    "#calculating NVocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "#setting smoothing parameter to 1 (Laplace smoothing)\n",
    "alfa = 1\n",
    "\n",
    "#calculating probability of spam.\n",
    "p_spam = len(spam_sms)/len(train_set)\n",
    "#calculating probability of ham\n",
    "p_ham = len(ham_sms)/len(train_set)\n",
    "\n",
    "print(\"P(spam) = {}\".format(round(p_spam, 2)))\n",
    "print(\"P(ham) = {}\".format(round(p_ham, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\begin{equation}\\text{Calculating }P(w_i|Spam)  \\text{ and } P(w_i|Ham)\\end{equation}\n",
    "Above we calculated the terms in the equations that will have constant values for every new message (regardless of the message or each individual word in the message).\n",
    "\n",
    "However, P(wi|Spam) and P(wi|Ham) will vary depending on the individual words. For instance, P(\"secret\"|Spam) will have a certain probability value, while P(\"cousin\"|Spam) or P(\"lovely\"|Spam) will most likely have other values.\n",
    "\n",
    "Although both P(wi|Spam) and P(wi|Ham) vary depending on the word, the probability for each individual word is constant for every new message.\n",
    "\n",
    "Which means we can use our training set to calculate the probability for each word in our vocabulary.\n",
    "\n",
    "We have 7,783 words in our vocabulary, which means we'll need to calculate a total of 15,566 probabilities. For each word, we need to calculate both P(wi|Spam) and P(wi|Ham).\n",
    "\n",
    "These probability values are better known as the **parameters**, so lets now calculate the parameters using the following equations for P(wi|Spam) and P(wi|Ham):\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} \\\\\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'foley': 0.0001305880816610804, '02': 0.0003482348844295477, 'strongly': 4.3529360553693465e-05, 'perpetual': 4.3529360553693465e-05, 'fish': 4.3529360553693465e-05, 'conserve': 4.3529360553693465e-05, 'series': 4.3529360553693465e-05, 'farm': 4.3529360553693465e-05, 'embarassed': 4.3529360553693465e-05, 'vale': 4.3529360553693465e-05}\n"
     ]
    }
   ],
   "source": [
    "#dicts to hold parameters\n",
    "spam_parameter = {word: 0 for word in vocabulary}\n",
    "ham_parameter = {word: 0 for word in vocabulary}\n",
    "\n",
    "#calculating params and updating dicts.\n",
    "for w in vocabulary:\n",
    "    word_i_giv_spam = (spam_sms[w].sum() + alfa) / (n_spam.sum() + alfa * n_vocabulary)\n",
    "    word_i_giv_ham = (ham_sms[w].sum() + alfa) / (n_ham.sum() + alfa * n_vocabulary)\n",
    "    spam_parameter[w] = word_i_giv_spam\n",
    "    ham_parameter[w] = word_i_giv_ham\n",
    "    \n",
    "#print first 10 spam parameters.    \n",
    "first10_spam_params = {k: spam_parameter[k] for k in list(spam_parameter)[:10]}\n",
    "print(first10_spam_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build The Spam Filter\n",
    "\n",
    "We've calculated all the constants and parameters, so we can now build our spam filter using the first two equations we mentioned:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#function takes message as a string\n",
    "def classify(string):\n",
    "    message = re.sub('\\W', ' ', string)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for w in message:\n",
    "        if w in spam_parameter:\n",
    "            p_spam_given_message *= spam_parameter[w]\n",
    "        if w in ham_parameter:\n",
    "            p_ham_given_message *= ham_parameter[w]\n",
    "            \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')\n",
    "                \n",
    "#Use the classify() function to classify two new messages.\n",
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying The Test Set\n",
    "\n",
    "So far our spam filter seem to be doing a good job, now let's determine how well it does clasifying the 1,114 messages in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the function to return labels instead of pinting them.\n",
    "def classify_test_set(string):\n",
    "    message = re.sub('\\W', ' ', string)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for w in message:\n",
    "        if w in spam_parameter:\n",
    "            p_spam_given_message *= spam_parameter[w]\n",
    "        if w in ham_parameter:\n",
    "            p_ham_given_message *= ham_parameter[w]\n",
    "            \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return ' needs human classification'\n",
    "        \n",
    "#create new column in test set with predicted labels.    \n",
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Accuracy of the Spam Filter\n",
    "\n",
    "Now that we have made our predictions, we can compare them with the true labels to see how accurate our spam filter is.\n",
    "\n",
    "To make the measurement, we'll use **accuracy** as a metric:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Accuracy} = \\frac{\\text{number of correctly classified messages}}{\\text{total number of classified messages}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9874326750448833\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "#total number of messages in the test set.\n",
    "total = test_set.shape[0]\n",
    "\n",
    "for index, row in test_set.iterrows():\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "    \n",
    "accruacy = correct/total\n",
    "print(accruacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial goal was to achieve an accuracy greater than 80%, with our test set we managed to get **an accuracy of 98.74%**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
